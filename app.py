# omr_grader_app.py
# Streamlit OMR Bubble Grader (rewritten from scratch)
# Goals:
# - Robust sheet detection & perspective correction
# - Bubble grid discovery via clustering (no hard-coded 3 columns / fixed counts)
# - Per-question bubble choice via fill-ratio scoring + ambiguity detection
# - Visual debug overlays + confidence metrics

import streamlit as st
import cv2
import numpy as np
import pandas as pd
from PIL import Image

# ---------------------------
# CONFIG
# ---------------------------
st.set_page_config(page_title="Yuva Gyan AI Vision Grader", layout="wide")

# 1..60 answer key uses 1..4 (A..D). We'll convert to 0..3 internally.
ANS_KEY = {
    1: 2, 2: 4, 3: 2, 4: 2, 5: 2, 6: 1, 7: 1, 8: 1, 9: 4, 10: 2,
    11: 1, 12: 1, 13: 4, 14: 1, 15: 2, 16: 1, 17: 4, 18: 2, 19: 2, 20: 3,
    21: 4, 22: 2, 23: 1, 24: 2, 25: 4, 26: 1, 27: 3, 28: 4, 29: 4, 30: 3,
    31: 1, 32: 3, 33: 2, 34: 2, 35: 3, 36: 2, 37: 4, 38: 3, 39: 1, 40: 4,
    41: 2, 42: 1, 43: 4, 44: 3, 45: 2, 46: 3, 47: 1, 48: 1, 49: 1, 50: 1,
    51: 1, 52: 2, 53: 2, 54: 4, 55: 2, 56: 3, 57: 1, 58: 2, 59: 2, 60: 2
}
OPTS = {0: "A", 1: "B", 2: "C", 3: "D"}

# ---------------------------
# UTILITIES
# ---------------------------
def pil_to_bgr(uploaded_file) -> np.ndarray:
    img = Image.open(uploaded_file).convert("RGB")
    arr = np.array(img)
    return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)

def order_points(pts: np.ndarray) -> np.ndarray:
    # pts: (4,2)
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]  # tl
    rect[2] = pts[np.argmax(s)]  # br
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]  # tr
    rect[3] = pts[np.argmax(diff)]  # bl
    return rect

def four_point_warp(image: np.ndarray, pts: np.ndarray, out_w=1400, out_h=1900) -> np.ndarray:
    rect = order_points(pts.astype("float32"))
    (tl, tr, br, bl) = rect

    dst = np.array([
        [0, 0],
        [out_w - 1, 0],
        [out_w - 1, out_h - 1],
        [0, out_h - 1]
    ], dtype="float32")

    M = cv2.getPerspectiveTransform(rect, dst)
    return cv2.warpPerspective(image, M, (out_w, out_h))

def largest_quad_contour(gray: np.ndarray) -> np.ndarray | None:
    # Stronger document detection: edges + close gaps, then find biggest 4-point contour.
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blur, 60, 180)

    # Close gaps: dilate then erode (closing-like)
    k = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))
    edges = cv2.dilate(edges, k, iterations=2)
    edges = cv2.erode(edges, k, iterations=1)

    cnts, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts:
        return None

    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)

    for c in cnts[:10]:
        peri = cv2.arcLength(c, True)
        approx = cv2.approxPolyDP(c, 0.02 * peri, True)
        if len(approx) == 4 and cv2.contourArea(approx) > 0.25 * gray.shape[0] * gray.shape[1]:
            return approx.reshape(4, 2)
    return None

def adaptive_binarize(gray: np.ndarray) -> np.ndarray:
    # More stable than global Otsu when lighting is uneven
    gray = cv2.GaussianBlur(gray, (3, 3), 0)
    th = cv2.adaptiveThreshold(
        gray, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV,
        35, 8
    )
    return th

def estimate_bubble_candidates(bin_img: np.ndarray, min_area=250, max_area=5000):
    """
    Find bubble-like contours using geometry:
    - area range
    - circularity
    - bounding box squareness
    Returns list of dicts: {contour, cx, cy, area, bbox(w,h), circularity}
    """
    cnts, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    candidates = []

    for c in cnts:
        area = cv2.contourArea(c)
        if area < min_area or area > max_area:
            continue

        x, y, w, h = cv2.boundingRect(c)
        if w < 12 or h < 12:
            continue

        ar = w / float(h)
        if ar < 0.75 or ar > 1.30:
            continue

        peri = cv2.arcLength(c, True)
        if peri <= 0:
            continue
        circularity = 4.0 * np.pi * area / (peri * peri)
        # circles ~1.0, squares ~0.78, noisy shapes lower
        if circularity < 0.55:
            continue

        M = cv2.moments(c)
        if abs(M["m00"]) < 1e-6:
            continue
        cx = float(M["m10"] / M["m00"])
        cy = float(M["m01"] / M["m00"])

        candidates.append({
            "contour": c,
            "cx": cx,
            "cy": cy,
            "area": area,
            "w": w,
            "h": h,
            "circularity": circularity
        })

    return candidates

def robust_scale_from_candidates(cands):
    # Use median bubble size as scale reference
    if not cands:
        return None
    ws = np.array([d["w"] for d in cands], dtype=np.float32)
    hs = np.array([d["h"] for d in cands], dtype=np.float32)
    return float(np.median((ws + hs) / 2.0))

def cluster_sorted(values, gap):
    """
    Cluster 1D values into groups by max gap.
    values must be sorted.
    """
    groups = []
    cur = []
    for v in values:
        if not cur:
            cur = [v]
            continue
        if abs(v - cur[-1]) <= gap:
            cur.append(v)
        else:
            groups.append(cur)
            cur = [v]
    if cur:
        groups.append(cur)
    return groups

def assign_to_nearest_group(v, group_centers):
    idx = int(np.argmin([abs(v - c) for c in group_centers]))
    return idx

def build_grid(cands, bubble_scale, expected_questions=60, expected_options=4):
    """
    Make the algorithm layout-agnostic:
    - Cluster y into "rows" (questions)
    - Cluster x into "option columns" (A..D) within each row via global x clusters
    Returns:
    - rows: list of rows, each row is list of candidate dicts
    - x_centers: option x centers sorted left->right
    """
    pts = np.array([(d["cx"], d["cy"]) for d in cands], dtype=np.float32)
    xs = np.sort(pts[:, 0])
    ys = np.sort(pts[:, 1])

    # Heuristic gaps based on bubble scale
    # row gap should be ~ bubble_scale * 1.2 to 2.0 depending on sheet
    row_gap = max(18.0, bubble_scale * 1.35)
    col_gap = max(18.0, bubble_scale * 1.35)

    # Cluster Y positions to rows
    y_groups = cluster_sorted(ys.tolist(), gap=row_gap)
    y_centers = [float(np.mean(g)) for g in y_groups]

    # Cluster X positions to columns (ideally 4 clusters for A-D)
    x_groups = cluster_sorted(xs.tolist(), gap=col_gap)
    x_centers = [float(np.mean(g)) for g in x_groups]
    x_centers.sort()

    # If too many x clusters (noise), reduce by taking strongest 4 via membership
    # Count membership per center by assigning each cand to nearest center
    counts = np.zeros(len(x_centers), dtype=int)
    for d in cands:
        ci = assign_to_nearest_group(d["cx"], x_centers)
        counts[ci] += 1

    if len(x_centers) > expected_options:
        # keep top expected_options by counts, then re-sort by x
        top_idx = np.argsort(counts)[::-1][:expected_options]
        x_centers = sorted([x_centers[i] for i in top_idx])

    # Rebuild rows: assign each bubble to nearest y center
    rows = [[] for _ in range(len(y_centers))]
    for d in cands:
        ri = assign_to_nearest_group(d["cy"], y_centers)
        rows[ri].append(d)

    # Sort rows top->bottom by center
    row_order = np.argsort(y_centers)
    rows = [rows[i] for i in row_order]

    # Within each row: keep bubbles that fall near the 4 x centers, select best match per option
    cleaned_rows = []
    for r in rows:
        if not r:
            continue

        # For each option index, select the bubble closest to its x center
        per_opt = [[] for _ in range(len(x_centers))]
        for d in r:
            ci = assign_to_nearest_group(d["cx"], x_centers)
            per_opt[ci].append(d)

        chosen = []
        for ci, bucket in enumerate(per_opt):
            if not bucket:
                continue
            # choose closest in x (and y) to the expected center; helps reject nearby noise
            bucket.sort(key=lambda dd: abs(dd["cx"] - x_centers[ci]) + 0.25 * abs(dd["cy"] - np.mean([x["cy"] for x in r])))
            chosen.append(bucket[0])

        # sort chosen by x
        chosen.sort(key=lambda dd: dd["cx"])
        cleaned_rows.append(chosen)

    return cleaned_rows, x_centers

def fill_score(bin_img, contour):
    # Score filled-ness inside contour: ratio of white pixels in bubble mask
    mask = np.zeros(bin_img.shape, dtype=np.uint8)
    cv2.drawContours(mask, [contour], -1, 255, -1)
    inside = cv2.bitwise_and(bin_img, bin_img, mask=mask)
    filled = cv2.countNonZero(inside)
    area = cv2.countNonZero(mask)
    if area <= 0:
        return 0.0, 0, 0
    return filled / float(area), filled, area

def grade_rows(rows, bin_img, roi_bgr, expected_questions=60):
    """
    Decision logic:
    - Compute fill ratio per option
    - Blank if max_ratio < blank_thresh
    - Double if 2nd is close to best (relative) AND both above mark_thresh
    """
    mark_thresh = 0.22   # tune: typical filled bubble ratio
    blank_thresh = 0.12  # tune: below this considered blank
    double_rel = 0.85    # second/best >= this -> double

    results = {"correct": 0, "wrong": 0, "blank": 0, "double": 0}
    logs = []

    q = 1
    for r in rows:
        if q > expected_questions:
            break

        # If row doesn't have 4 detected bubbles, mark as problematic
        if len(r) < 4:
            logs.append({
                "Q": q, "Status": "Missing bubbles", "Picked": None, "Answer": OPTS.get(ANS_KEY[q]-1, "?"),
                "Confidence": 0.0
            })
            results["wrong"] += 1
            q += 1
            continue

        # Compute ratios for first 4 after sorting
        r = sorted(r[:4], key=lambda d: d["cx"])
        ratios = []
        for j in range(4):
            ratio, filled, area = fill_score(bin_img, r[j]["contour"])
            ratios.append((ratio, j, filled, area))

        ratios.sort(key=lambda x: x[0], reverse=True)
        best, best_j = ratios[0][0], ratios[0][1]
        second = ratios[1][0]

        k = ANS_KEY.get(q, -1) - 1  # correct choice 0..3

        status = ""
        picked = None
        confidence = float(np.clip((best - second) / max(best, 1e-6), 0, 1))

        # Visual helpers
        def draw(idx, color, thickness=3):
            cv2.drawContours(roi_bgr, [r[idx]["contour"]], -1, color, thickness)

        if best < blank_thresh:
            status = "Blank"
            results["blank"] += 1
            picked = None
            if 0 <= k < 4:
                draw(k, (255, 0, 0), 2)

        else:
            # consider "marked" if above mark_thresh
            marked = [x for x in ratios if x[0] >= mark_thresh]
            if len(marked) >= 2 and (second >= best * double_rel):
                status = "Double"
                results["double"] += 1
                results["wrong"] += 1
                # draw top 2 in yellow
                draw(ratios[0][1], (0, 255, 255), 3)
                draw(ratios[1][1], (0, 255, 255), 3)
                if 0 <= k < 4:
                    draw(k, (255, 0, 0), 2)
            else:
                picked = best_j
                if picked == k:
                    status = "Correct"
                    results["correct"] += 1
                    draw(picked, (0, 255, 0), 3)
                else:
                    status = "Incorrect"
                    results["wrong"] += 1
                    draw(picked, (0, 0, 255), 3)
                    if 0 <= k < 4:
                        draw(k, (255, 0, 0), 2)

        logs.append({
            "Q": q,
            "Status": status,
            "Picked": OPTS.get(picked, None) if picked is not None else None,
            "Answer": OPTS.get(k, "?") if 0 <= k < 4 else "?",
            "BestFill": round(best, 3),
            "SecondFill": round(second, 3),
            "Confidence": round(confidence, 3),
        })
        q += 1

    return results, logs

# ---------------------------
# MAIN PIPELINE
# ---------------------------
def process_omr(image_bgr: np.ndarray, expected_questions=60):
    debug = {}

    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    quad = largest_quad_contour(gray)

    if quad is None:
        # fallback: whole image
        h, w = image_bgr.shape[:2]
        quad = np.array([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]], dtype=np.float32)
        debug["doc_detect"] = "fallback_full_image"
    else:
        debug["doc_detect"] = "quad_found"

    warped = four_point_warp(image_bgr, quad, out_w=1400, out_h=1900)

    # ROI: try to focus on bubble area; keep configurable sliders in UI
    # Default values are conservative; adjust per sheet design
    roi_top, roi_bottom = 320, 1840
    roi_left, roi_right = 40, 1360
    roi = warped[roi_top:roi_bottom, roi_left:roi_right].copy()
    roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)

    # Binarize
    bin_img = adaptive_binarize(roi_gray)

    # Clean small noise
    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    bin_clean = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, k, iterations=1)

    # Detect bubble candidates
    cands = estimate_bubble_candidates(bin_clean, min_area=260, max_area=7000)
    debug["candidates"] = len(cands)

    if len(cands) < 50:
        return None, roi, None, {"error": "Too few bubble-like shapes detected. Try better scan / lighting."}, debug

    scale = robust_scale_from_candidates(cands)
    if scale is None:
        return None, roi, None, {"error": "Unable to estimate bubble scale."}, debug

    rows, x_centers = build_grid(cands, scale, expected_questions=expected_questions, expected_options=4)
    debug["rows_detected"] = len(rows)
    debug["x_centers"] = [round(x, 1) for x in x_centers]

    # Create AI-view overlay
    overlay = roi.copy()

    # draw all candidate contours faint
    for d in cands:
        cv2.drawContours(overlay, [d["contour"]], -1, (80, 80, 80), 1)

    # Grade
    stats, logs = None, None
    stats, logs = grade_rows(rows, bin_clean, overlay, expected_questions=expected_questions)

    return stats, overlay, bin_clean, {"message": "Success"}, debug

# ---------------------------
# STREAMLIT UI
# ---------------------------
st.title("AI Vision OMR Grader (Ultra-Robust)")
st.caption("Robust bubble detection using adaptive threshold + circularity + clustering. Works across multi-column layouts without hard-coding 3 columns.")

uploaded = st.file_uploader("Upload OMR image", type=["jpg", "jpeg", "png"])

with st.expander("Settings (only change if needed)", expanded=False):
    expected_questions = st.number_input("Expected Questions", min_value=10, max_value=300, value=60, step=1)
    st.write("Tip: If your sheet has 100 questions, set this to 100.")

if uploaded:
    img = pil_to_bgr(uploaded)

    with st.spinner("Detecting sheet, bubbles and grading..."):
        stats, out_img, bin_img, msg, debug = process_omr(img, expected_questions=int(expected_questions))

    if stats is None:
        st.error(msg.get("error", "Unknown error"))
        st.write("Debug:", debug)
        st.image(out_img, channels="BGR", use_container_width=True)
    else:
        st.success(f"Done. Rows detected: {debug.get('rows_detected')} | Bubble candidates: {debug.get('candidates')}")
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("âœ… Correct", stats["correct"])
        c2.metric("âŒ Wrong", stats["wrong"])
        c3.metric("â¬œ Blank", stats["blank"])
        c4.metric("âš ï¸ Double", stats["double"])

        t1, t2, t3 = st.tabs(["ðŸ–¼ï¸ AI View", "ðŸ§  Binary View", "ðŸ“Š Logs"])
        with t1:
            st.image(out_img, channels="BGR", use_container_width=True)
            st.caption("Green=correct picked, Red=wrong picked, Blue=correct answer, Yellow=double marks. Gray outlines=all bubble candidates.")
            st.write("Debug:", debug)

        with t2:
            st.image(bin_img, clamp=True, use_container_width=True)
            st.caption("Binary (inverted): filled marks appear white. If this looks bad, improve scan/lighting.")

        with t3:
            df = pd.DataFrame(debug and [])  # placeholder to keep UI stable if needed
            # show logs
            # (Recompute logs from stats? logs are inside grade_rows; expose by slight tweak)
            # We'll regenerate by calling again cheaply: kept simple by storing in session.
            # Instead, easiest: add logs return via session_state.
            st.info("To export logs, add a CSV download button below (optional).")
